1
0:00:00,880 --> 0:00:02,720
hey guys welcome to digital swinney

2
0:00:02,720 --> 0:00:04,480
channel on youtube and if you haven't

3
0:00:04,480 --> 0:00:06,160
already done so please go ahead and hit

4
0:00:06,160 --> 0:00:07,040
the subscribe

5
0:00:07,040 --> 0:00:10,080
button because i know you're going to

6
0:00:10,080 --> 0:00:12,160
love the content i have

7
0:00:12,160 --> 0:00:14,320
and the content that i know i'll be

8
0:00:14,320 --> 0:00:15,839
putting on this channel

9
0:00:15,839 --> 0:00:17,760
in future okay now let's get to the

10
0:00:17,760 --> 0:00:18,960
topic of this

11
0:00:18,960 --> 0:00:21,600
video in fact it's the topic of this one

12
0:00:21,600 --> 0:00:23,840
and the next video in these two videos

13
0:00:23,840 --> 0:00:24,880
we are going to learn

14
0:00:24,880 --> 0:00:28,640
about how we can pre-train a unit

15
0:00:28,640 --> 0:00:31,039
using auto encoders what do i mean by

16
0:00:31,039 --> 0:00:31,679
that

17
0:00:31,679 --> 0:00:33,440
well when you define unit or when you

18
0:00:33,440 --> 0:00:36,719
define any neural network

19
0:00:36,719 --> 0:00:39,120
you're going to initialize the weights

20
0:00:39,120 --> 0:00:40,640
right the whole point of training a

21
0:00:40,640 --> 0:00:41,600
neural network

22
0:00:41,600 --> 0:00:44,879
is learning the weights

23
0:00:44,879 --> 0:00:47,840
and biases using your back propagation

24
0:00:47,840 --> 0:00:48,320
you're

25
0:00:48,320 --> 0:00:50,640
updating the weights checking the result

26
0:00:50,640 --> 0:00:51,760
updating the weights

27
0:00:51,760 --> 0:00:54,480
checking the result until you're happy

28
0:00:54,480 --> 0:00:54,879
with

29
0:00:54,879 --> 0:00
the metric that you're tracking okay now

30
0:00 --> 0:01:00,960
when you're updating these weights you

31
0:01:00,960 --> 0:01:02,239
hope that it's heading in the right

32
0:01:02,239 --> 0:01:04,159
direction hopefully it will if you pick

33
0:01:04,159 --> 0:01:06,159
your loss function and your optimizers

34
0:01:06,159 --> 0:01
the right way but

35
0:01 --> 0:01:09,600
typically the weights are assigned in a

36
0:01:09,600 --> 0:01:11,520
random way

37
0:01:11,520 --> 0:01:14,960
okay you can use transfer learning and

38
0:01:14,960 --> 0:01:16,799
where transfer learning helps

39
0:01:16,799 --> 0:01:19,040
is you already know that there is a

40
0:01:19,040 --> 0:01:21,119
model that has been trained on millions

41
0:01:21,119 --> 0:01:22,799
of images so let's go ahead and start

42
0:01:22,799 --> 0:01:24,320
with those weights

43
0:01:24,320 --> 0:01:27,119
meaning they probably already know how

44
0:01:27,119 --> 0:01:28,960
to detect certain edges or

45
0:01:28,960 --> 0:01:31,360
you know uh rounded features and so on

46
0:01:31,360 --> 0:01:33,040
and then you go from there so what i'm

47
0:01:33,040 --> 0:01:33,920
proposing here

48
0:01:33,920 --> 0:01:36,240
is very similar to that except instead

49
0:01:36,240 --> 0:01:37,920
of using pre-trained

50
0:01:37,920 --> 0:01:41,119
weights from imagenet and vgg or

51
0:01:41,119 --> 0:01
something

52
0:01 --> 0:01:44,479
i'm talking about using your own auto

53
0:01:44,479 --> 0:01:45,520
encoder

54
0:01:45,520 --> 0:01:48,560
on your own data and then generating

55
0:01:48,560 --> 0:01:51,759
weights okay so what do i mean by that

56
0:01:51,759 --> 0:01:54,880
now you have let's say hundreds of uh

57
0:01:54,880 --> 0:01:56,960
hundreds of electron microscopy images

58
0:01:56,960 --> 0:01:58,159
or some images right

59
0:01:58,159 --> 0:01:59,680
and you know that in future you'll be

60
0:01:59,680 --> 0:02:01,840
keep working on these and then you're

61
0:02:01,840 --> 0:02:04,240
you're trying to train a model it makes

62
0:02:04,240 --> 0:02:06,159
sense for you to put some time

63
0:02:06,159 --> 0:02:09,200
ahead of time in generating

64
0:02:09,200 --> 0:02:11,520
uh in generating the initial weights

65
0:02:11,520 --> 0:02:13,360
instead of starting with random weights

66
0:02:13,360 --> 0:02:16,319
start with a weights where it has been

67
0:02:16,319 --> 0:02:17,680
trained on your

68
0:02:17,680 --> 0:02
own data this is exactly what we are

69
0:02 --> 0:02:20,800
talking about

70
0:02:20,800 --> 0:02:22,640
now how do you generate these weights if

71
0:02:22,640 --> 0:02:24,160
you don't have the labels right i mean

72
0:02:24,160 --> 0:02:25,280
in unit

73
0:02:25,280 --> 0:02:27,200
you have you have your images and you

74
0:02:27,200 --> 0:02:28,800
have your uh masks

75
0:02:28,800 --> 0:02
and your training on it well that is

76
0:02 --> 0:02:33,920
exactly where auto encoders come into

77
0:02:33,920 --> 0:02:34,400
picture

78
0:02:34,400 --> 0:02:37,360
what is an auto encoder it learns how to

79
0:02:37,360 --> 0:02:38,400
reconstruct your

80
0:02:38,400 --> 0:02:41,120
image based on you know your input image

81
0:02:41,120 --> 0:02:42,959
it learns how to reconstruct your input

82
0:02:42,959 --> 0:02:44,800
image in this example you can see how

83
0:02:44,800 --> 0:02:45,360
you have

84
0:02:45,360 --> 0:02:47,200
a reconstructed image this is an actual

85
0:02:47,200 --> 0:02:48,959
reconstructed image and not the same

86
0:02:48,959 --> 0:02:49,599
image

87
0:02:49,599 --> 0:02:52,640
okay so you train this network

88
0:02:52,640 --> 0:02:55,920
where it goes from a larger size to a

89
0:02:55,920 --> 0:02:58,400
incrementally smaller uh if that's a

90
0:02:58,400 --> 0:02:59,519
word it

91
0:02:59,519 --> 0:03:01,680
incrementally smaller you know

92
0:03:01,680 --> 0:03:03,599
representation of your image

93
0:03:03,599 --> 0:03:05,280
and then you're decoding it back to

94
0:03:05,280 --> 0:03:08,239
original in this process

95
0:03:08,239 --> 0:03:10,560
when you're doing this we are updating

96
0:03:10,560 --> 0:03:12,159
the weights of all of these

97
0:03:12,159 --> 0:03:15,599
and i'm proposing train that do that and

98
0:03:15,599 --> 0:03:18,560
take the weights from your encoder and

99
0:03:18,560 --> 0:03:19,200
use them

100
0:03:19,200 --> 0:03:21,200
as part of your unit because unit is

101
0:03:21,200 --> 0:03:23,040
nothing but an encoder

102
0:03:23,040 --> 0:03:25,840
decoder network just like auto encoder

103
0:03:25,840 --> 0:03:26,560
so

104
0:03:26,560 --> 0:03:29,840
uh let's uh get into the next level so

105
0:03:29,840 --> 0:03:30,560
we can

106
0:03:30,560 --> 0:03
understand this and then we'll get into

107
0:03 --> 0:03:33,680
code in a minute okay so i just

108
0:03:33,680 --> 0:03:35,440
explained that this is your encoder

109
0:03:35,440 --> 0:03
right in an

110
0:03 --> 0:03:38,640
auto encoder network now what happens

111
0:03:38,640 --> 0:03:40,159
like when you send an image

112
0:03:40,159 --> 0:03:43,599
through it trains this network may take

113
0:03:43,599 --> 0:03:45,519
i don't know how many ever epochs

114
0:03:45,519 --> 0:03:47,840
and then at some point you're like okay

115
0:03:47,840 --> 0:03:48,959
let me

116
0:03:48,959 --> 0:03:50,480
send you an input image and then it

117
0:03:50,480 --> 0:03:52,319
reconstructs that input image back

118
0:03:52,319 --> 0:03:54,080
right so this is the definition of auto

119
0:03:54,080 --> 0:03:56,560
encoder during the training process it

120
0:03:56,560 --> 0:03:57,920
learns different features

121
0:03:57,920 --> 0:04:00,959
at different uh depths and

122
0:04:00,959 --> 0:04:03,280
it learns uh i don't know the edges are

123
0:04:03,280 --> 0:04:05,120
the basic you know you see how there are

124
0:04:05,120 --> 0:04:06,480
certain edges going on

125
0:04:06,480 --> 0:04:09,200
uh right there in mona lisa and in some

126
0:04:09,200 --> 0:04:10,560
images you can see that

127
0:04:10,560 --> 0:04:12,560
and as you go deeper and deeper it's

128
0:04:12,560 --> 0:04:14,080
actually learning higher and higher

129
0:04:14,080 --> 0:04
features in fact the outer layer

130
0:04 --> 0:04:17,359
features uh

131
0:04:17,359 --> 0:04:19,280
may look the same between random

132
0:04:19,280 --> 0:04:20,400
initialized weights

133
0:04:20,400 --> 0:04:22,240
and pre-trained weights but as you go

134
0:04:22,240 --> 0:04:23,919
deeper and deeper this is where you

135
0:04:23,919 --> 0:04:25,440
actually see some difference because

136
0:04:25,440 --> 0:04:27,759
this is where the it's it's feature rich

137
0:04:27,759 --> 0:04:28,479
now

138
0:04:28,479 --> 0:04:31,840
okay at outer layers it has a very much

139
0:04:31,840 --> 0:04:35,280
uh uh knowledge of pixel awareness let's

140
0:04:35,280 --> 0:04:36,080
say

141
0:04:36,080 --> 0:04:38,320
as you go deeper and deeper it's more

142
0:04:38,320 --> 0:04:39,440
feature-rich

143
0:04:39,440 --> 0:04:42,240
okay so that's why it's it's uh if we

144
0:04:42,240 --> 0:04:43,440
can pre-train this

145
0:04:43,440 --> 0:04:45,520
and take these weights and use it as

146
0:04:45,520 --> 0:04:47,840
part of unit that would be amazing so

147
0:04:47,840 --> 0:04:50,560
let me just show you a few of these uh

148
0:04:50,560 --> 0:04:51,840
uh

149
0:04:51,840 --> 0:04:53,520
you know similarities first of all let's

150
0:04:53,520 --> 0:04:55,040
start with similarity between auto

151
0:04:55,040 --> 0:04:56,639
encoder and a unit right

152
0:04:56,639 --> 0:04:58,560
so if you look at auto encoder again

153
0:04:58,560 --> 0:05
this is the third time we are seeing in

154
0:05 --> 0:05:01,360
this part of presentation

155
0:05:01,360 --> 0:05:03,360
this first part is encoder because we

156
0:05:03,360 --> 0:05:05,280
are encoding a larger size image into a

157
0:05:05,280 --> 0:05:07,199
smaller size and then we are decoding

158
0:05:07,199 --> 0:05:08,720
this part is the decoder

159
0:05:08,720 --> 0:05:10,560
so if you look at a unit hopefully you

160
0:05:10,560 --> 0:05:12,479
watched my the last

161
0:05:12,479 --> 0:05:14,160
30 videos or so where we have been

162
0:05:14,160 --> 0:05:15,919
talking about unit so if you look at

163
0:05:15,919 --> 0:05:16,720
unit this is

164
0:05:16,720 --> 0:05:18,800
exactly the same except you bend it into

165
0:05:18,800 --> 0:05:21,039
a u shape so you have a

166
0:05:21,039 --> 0:05:23,280
encoder right there right this is

167
0:05:23,280 --> 0:05:24,080
nothing but

168
0:05:24,080 --> 0:05:27,120
this yeah i just arranged it in such a

169
0:05:27,120 --> 0:05:28,080
way that it

170
0:05:28,080 --> 0:05:31,039
it can form a u using this that's it and

171
0:05:31,039 --> 0:05:33,199
you have a decoder so it's exactly this

172
0:05:33,199 --> 0:05:35,039
and that why is it called a unit because

173
0:05:35,039 --> 0:05:36,639
in addition to this

174
0:05:36,639 --> 0:05:39,680
in addition to an actual auto encoder

175
0:05:39,680 --> 0:05:43,039
we have skip connections meaning

176
0:05:43,039 --> 0:05:45,520
the information from this layer is going

177
0:05:45,520 --> 0:05:46,639
to that layer

178
0:05:46,639 --> 0:05:48,400
information from here is going to this

179
0:05:48,400 --> 0:05:50,160
layer y

180
0:05:50,160 --> 0:05:53,280
remember the earlier layers right here

181
0:05:53,280 --> 0:05:56,319
they have information about pixels as

182
0:05:56,319 --> 0:05:58,720
you go deeper you have information about

183
0:05:58,720 --> 0:06:00,800
features more information about features

184
0:06:00,800 --> 0:06:02,160
a combination of this

185
0:06:02,160 --> 0:06:04,960
gives you semantic segmentation uh pixel

186
0:06:04,960 --> 0:06:05,680
awareness

187
0:06:05,680 --> 0:06:08,400
plus the feature yeah so that's what a

188
0:06:08,400 --> 0:06:09,039
unit

189
0:06:09,039 --> 0:06:12,639
is this is exactly why i'm proposing to

190
0:06:12,639 --> 0:06:15,199
take uh if you have a million images

191
0:06:15,199 --> 0:06:16,479
that are completely

192
0:06:16,479 --> 0:06:18,960
unlabeled if you have labeled data

193
0:06:18,960 --> 0:06:19,680
that's fine

194
0:06:19,680 --> 0:06:22,240
go ahead and train a unit and then and

195
0:06:22,240 --> 0:06:23,600
then you're okay you don't need to spend

196
0:06:23,600 --> 0:06:25,360
this but then if you have one million

197
0:06:25,360 --> 0:06:27,280
unlabeled images how can you benefit

198
0:06:27,280 --> 0:06:28,400
from them by not

199
0:06:28,400 --> 0:06:30,960
labeling every image so just dump all

200
0:06:30,960 --> 0:06:32,160
those million images

201
0:06:32,160 --> 0:06:34,400
train an auto encoder and then just get

202
0:06:34,400 --> 0:06:36,319
the encoder part and use it as part of

203
0:06:36,319 --> 0:06:37,199
your unit

204
0:06:37,199 --> 0:06:39,039
this is exactly what i'm proposing right

205
0:06:39,039 --> 0:06:40,880
here okay so

206
0:06:40,880 --> 0:06:43,919
again information

207
0:06:43,919 --> 0:06
as you go deeper and deeper gets more

208
0:06 --> 0:06:48,160
feature rate so let's just compare that

209
0:06:48,160 --> 0:06:49,840
with a few features by the way when we

210
0:06:49,840 --> 0:06:51,680
jump into the code i'm going to show you

211
0:06:51,680 --> 0:06:53,120
a quick auto encoder

212
0:06:53,120 --> 0:06:55,280
and then how to print out these uh

213
0:06:55,280 --> 0:06:57,199
features at various depths

214
0:06:57,199 --> 0:06:59,840
of your of your network okay so we'll

215
0:06:59,840 --> 0:07:00,960
get there in a second

216
0:07:00,960 --> 0:07:04,160
so uh here is the feature output

217
0:07:04,160 --> 0:07:06,400
at layer number the first layer okay

218
0:07:06,400 --> 0:07
after the first layer this is not the

219
0:07 --> 0:07:09,759
input but after the first one

220
0:07:09,759 --> 0:07:11,759
a convolutional layer this is this is

221
0:07:11,759 --> 0:07:13,280
how your input looks

222
0:07:13,280 --> 0:07:16,639
uh sorry the features look like okay

223
0:07:16,639 --> 0:07:19,360
so as you can see i mean you can still

224
0:07:19,360 --> 0:07:20,880
see mona lisa right there

225
0:07:20,880 --> 0:07:22,400
so it's still trying to learn even

226
0:07:22,400 --> 0:07:24,080
though these are random weights but

227
0:07:24,080 --> 0:07:26,720
if you use a pre-trained network this is

228
0:07:26,720 --> 0:07
how the weights would look like

229
0:07 --> 0:07:30,160
it may not look that different but uh

230
0:07:30,160 --> 0:07:32,800
again if you try to squint your eyes

231
0:07:32,800 --> 0:07:35,120
you can see the difference uh where in

232
0:07:35,120 --> 0:07:36,560
this case where where you have

233
0:07:36,560 --> 0:07:38,400
pre-trained weight some of the features

234
0:07:38,400 --> 0:07:39,919
are you know right there some of the

235
0:07:39,919 --> 0:07:41,520
features you see the hot spots right

236
0:07:41,520 --> 0:07:42,800
there

237
0:07:42,800 --> 0:07:44,800
yeah you see hot spots wherever you see

238
0:07:44,800 --> 0:07:47,120
hot spots that means it's it's it's uh

239
0:07:47,120 --> 0:07:49,199
learning something uh right there yeah

240
0:07:49,199 --> 0:07:50,720
so that's the feature response right

241
0:07:50,720 --> 0:07:51,440
there

242
0:07:51,440 --> 0:07:53,599
so there you go and then let's go to

243
0:07:53,599 --> 0:07:56,560
layer number eight

244
0:07:56,560 --> 0:07
now you start to see the difference

245
0:07 --> 0:07:59,680
between random weights

246
0:07:59,680 --> 0:08:01,199
random weights still look pretty much

247
0:08:01,199 --> 0:08:02,720
the same as before right

248
0:08:02,720 --> 0:08:04,560
as the layer number one let's go back

249
0:08:04,560 --> 0:08:06,080
this is layer number zero

250
0:08:06,080 --> 0:08:08,240
these are all random weights this is

251
0:08:08,240 --> 0:08:09,199
pretty train weights

252
0:08:09,199 --> 0:08:11,599
this is layer eight looks very similar

253
0:08:11,599 --> 0:08:13,360
to layer 0

254
0:08:13,360 --> 0:08:15,440
because these are random weights and

255
0:08:15,440 --> 0:08:17,039
this is pre-trained now you see

256
0:08:17,039 --> 0:08:18,720
much more definition of the structure

257
0:08:18,720 --> 0:08:20,720
now let's go to layer 16

258
0:08:20,720 --> 0:08:22,720
again these are random weights at layer

259
0:08:22,720 --> 0:08:24,319
16 okay

260
0:08:24,319 --> 0:08:27,199
and this is pre-trained weights you

261
0:08:27,199 --> 0:08:28,160
already have

262
0:08:28,160 --> 0:08:30,960
a lot of rich information and finally

263
0:08:30,960 --> 0:08:31,840
let's look at

264
0:08:31,840 --> 0:08:34,719
well let's look at couple more layer 24

265
0:08:34,719 --> 0:08:35,200
again

266
0:08:35,200 --> 0:08:37,519
random weights everything random and

267
0:08:37,519 --> 0:08:39,120
here you start to see some structure

268
0:08:39,120 --> 0:08:40,719
they look a bit more blurry because we

269
0:08:40,719 --> 0:08:42,640
are going smaller in size

270
0:08:42,640 --> 0:08:44,720
and i'm expanding that that's the only

271
0:08:44,720 --> 0:08:46,640
reason they look very blurry compared to

272
0:08:46,640 --> 0:08:47,519
initial so

273
0:08:47,519 --> 0:08:51,440
as you go deeper features feature rich

274
0:08:51,440 --> 0:08:54,320
but not necessarily spatial rich okay so

275
0:08:54,320 --> 0:08:55,120
there you go so

276
0:08:55,120 --> 0:08:57,440
and finally 32 layer it's not like you

277
0:08:57,440 --> 0:08:58,240
don't even

278
0:08:58,240 --> 0:09
you see anything here you don't even see

279
0:09 --> 0:09:01,680
mona lisa anymore because these are all

280
0:09:01,680 --> 0:09:03,360
random weights again and again

281
0:09:03,360 --> 0:09:06,160
with the pre-trained weights you have

282
0:09:06,160 --> 0:09:07,200
hot spots

283
0:09:07,200 --> 0:09:09,680
showing something important something

284
0:09:09,680 --> 0:09:11,360
useful for segmentation uh

285
0:09:11,360 --> 0:09:13,440
for for for reconstruction right there

286
0:09:13,440 --> 0:09:14,399
okay so

287
0:09:14,399 --> 0:09:17,519
this is uh uh this is the thing that i

288
0:09:17,519 --> 0:09:19,360
wanted to convey in this video

289
0:09:19,360 --> 0:09:21,600
like remind you what an auto encoder is

290
0:09:21,600 --> 0:09:23,279
and how to extract features now let's

291
0:09:23,279 --> 0:09:24,320
jump into the code

292
0:09:24,320 --> 0:09:27,600
to repeat this okay

293
0:09:27,600 --> 0:09:30,240
okay so let's start by understanding

294
0:09:30,240 --> 0:09:32,560
single image reconstruction

295
0:09:32,560 --> 0:09:34,800
in this video just like what i've shown

296
0:09:34,800 --> 0:09:36,399
you in the presentation part

297
0:09:36,399 --> 0:09:37,760
and then look at some of the features

298
0:09:37,760 --> 0:09:39,279
i'll share the code so you can do this

299
0:09:39,279 --> 0:09:39,839
yourself

300
0:09:39,839 --> 0:09:42,320
this is a very educational thing to do

301
0:09:42,320 --> 0:09
if you want to get into

302
0:09 --> 0:09:46,560
auto encoders or even any any deep

303
0:09:46,560 --> 0:09:47,120
learning

304
0:09:47,120 --> 0:09:48,720
this this really helps you understand

305
0:09:48,720 --> 0:09:50,320
the features right at various

306
0:09:50,320 --> 0:09:53,440
various layers okay so uh

307
0:09:53,440 --> 0:09:55,120
where do we start first let's go ahead

308
0:09:55,120 --> 0:09:56,959
and import the required libraries

309
0:09:56,959 --> 0:09:59,360
matplotlib numpy opencv let's go ahead

310
0:09:59,360 --> 0:10:00,080
and do that

311
0:10:00,080 --> 0:10:02,480
this is actually first let's make sure

312
0:10:02,480 --> 0:10:03,680
we are in the right

313
0:10:03,680 --> 0:10:06,959
working directory so

314
0:10:06,959 --> 0:10:09,440
again i'm using python 3.7 and

315
0:10:09,440 --> 0:10:11,360
tensorflow 2.4

316
0:10:11,360 --> 0:10:12,800
so let's look at my present working

317
0:10:12,800 --> 0:10:14,560
directory that's definitely not where i

318
0:10:14,560 --> 0:10:15,200
want to be

319
0:10:15,200 --> 0:10:18,160
i can navigate through here or i'll just

320
0:10:18,160 --> 0:10:19,600
type some

321
0:10:19,600 --> 0:10:21,680
mistake right there and it says hey this

322
0:10:21,680 --> 0:10:23,279
is not

323
0:10:23,279 --> 0:10:26,079
good code you know this is a mistake so

324
0:10:26,079 --> 0:10:26,720
let's

325
0:10:26,720 --> 0:10:28,959
now if i do my directory it changes

326
0:10:28,959 --> 0:10:30,800
because the settings the way i have

327
0:10:30,800 --> 0:10:32,640
settings in my spider

328
0:10:32,640 --> 0:10:34,959
anytime i run a run a file it just

329
0:10:34,959 --> 0:10:36,399
automatically changes the working

330
0:10:36,399 --> 0:10:38,320
directory to that so this is the easiest

331
0:10:38,320 --> 0:10:40,320
way anyway little tricks

332
0:10:40,320 --> 0:10:43,600
now let's uh run these lines of code and

333
0:10:43,600 --> 0:10:46,800
let's also from uh from keras i'm going

334
0:10:46,800 --> 0:10:47,200
to

335
0:10:47,200 --> 0:10:50,320
why did i do tensorflow.python.keras

336
0:10:50,320 --> 0:10:54,800
sorry i am not supposed to edit the code

337
0:10:54,800 --> 0:10:55,200
while

338
0:10:55,200 --> 0:10:57,040
i'm doing a video because i have no clue

339
0:10:57,040 --> 0:10:58,640
how that's going to work out

340
0:10:58,640 --> 0:11:01,279
normally i just do from keras dot

341
0:11:01,279 --> 0:11:02,079
reprocessing

342
0:11:02,079 --> 0:11:04,240
import this from keras.layers import

343
0:11:04,240 --> 0:11:05,760
this but uh

344
0:11:05,760 --> 0:11:09,120
but since i switched to uh python two

345
0:11:09,120 --> 0:11:10,399
points something uh

346
0:11:10,399 --> 0:11:13,040
sorry tensorflow two point i started to

347
0:11:13,040 --> 0:11:14,800
do tensorflow.keras

348
0:11:14,800 --> 0:11:17,920
okay just my personal preference

349
0:11:17,920 --> 0:11:20,720
uh otherwise i used to directly import

350
0:11:20,720 --> 0:11:21,519
keras

351
0:11:21,519 --> 0:11:24,880
previously uh just just a habit

352
0:11:24,880 --> 0:11:28,240
okay so there you go so uh again i don't

353
0:11:28,240 --> 0:11:29,839
think we need these but

354
0:11:29,839 --> 0:11:31,920
this is something that i usually import

355
0:11:31,920 --> 0:11:33,040
if i'm trying to build

356
0:11:33,040 --> 0:11:35,120
a deep learning model okay we'll we'll

357
0:11:35,120 --> 0:11:36,399
go through these step by step in a

358
0:11:36,399 --> 0:11:38,399
second this is pretty straightforward

359
0:11:38,399 --> 0:11:41,760
i want to resize my image to 256 so i

360
0:11:41,760 --> 0:11:43,360
just defined it here and

361
0:11:43,360 --> 0:11:46,320
my image data which i'm going to capture

362
0:11:46,320 --> 0:11:47,440
am i going to capture

363
0:11:47,440 --> 0:11
image data i don't even i think yeah

364
0:11 --> 0:11:50,480
right there

365
0:11:50,480 --> 0:11:53,040
image data empty list because i want to

366
0:11:53,040 --> 0:11:53,600
append

367
0:11:53,600 --> 0:11:55,600
my image into array this can be useful

368
0:11:55,600 --> 0:11:57,200
if you have multiple images right so

369
0:11:57,200 --> 0:11:59,120
anyway let's go ahead and define this

370
0:11:59,120 --> 0:12:01,279
and i'm going to read my mona lisa image

371
0:12:01,279 --> 0:12:02,720
right there as color

372
0:12:02,720 --> 0:12:06,800
yeah all channels and convert my color

373
0:12:06,800 --> 0:12:08,399
from bgr to rgb

374
0:12:08,399 --> 0:12:10,240
that's not a necessary step but i do

375
0:12:10,240 --> 0:12:12,079
that usually if i want to visualize

376
0:12:12,079 --> 0:12:13,760
things so that makes it easy for us to

377
0:12:13,760 --> 0:12:15,120
intuitively understand

378
0:12:15,120 --> 0:12:16,959
what's going on okay now i'm going to

379
0:12:16,959 --> 0:12:18,560
resize my image

380
0:12:18,560 --> 0:12:21,279
i think this is probably 256 to begin

381
0:12:21,279 --> 0:12:22,959
with but

382
0:12:22,959 --> 0:12:24,959
that's okay i mean i'm why am i resizing

383
0:12:24,959 --> 0:12
because my network

384
0:12 --> 0:12:29,040
expects 256 that's pretty much it

385
0:12:29,040 --> 0:12:31,600
okay now let's go ahead and image data

386
0:12:31,600 --> 0:12:33,200
dot append

387
0:12:33,200 --> 0:12:36,639
and finally even reshape this array

388
0:12:36,639 --> 0:12:39,920
why am i doing all of this because

389
0:12:39,920 --> 0:12:42,480
for the network i want my input to be in

390
0:12:42,480 --> 0:12:43,279
the shape of

391
0:12:43,279 --> 0:12:46,560
n x y and number of channels right n

392
0:12:46,560 --> 0:12:49,519
is number of images x y image dimensions

393
0:12:49,519 --> 0:12:51,120
and number of channels this is

394
0:12:51,120 --> 0:12:53,839
obviously uh you you probably know that

395
0:12:53,839 --> 0:12:55,279
anyway let's go ahead and divide the

396
0:12:55,279 --> 0:12:57,120
pixels by 255 so it's a

397
0:12:57,120 --> 0:12:59,200
it's a way of scaling so now i'm all

398
0:12:59,200 --> 0:13:00,560
ready my image area

399
0:13:00,560 --> 0:13:03,600
is float32 so up to this point i should

400
0:13:03,600 --> 0:13:05,360
probably have skipped through this

401
0:13:05,360 --> 0:13:07,279
and just said i'm loading an image

402
0:13:07,279 --> 0:13:09,360
that's it right but again

403
0:13:09,360 --> 0:13:11,279
my viewers come with various backgrounds

404
0:13:11,279 --> 0:13:13,120
so this hopefully can help

405
0:13:13,120 --> 0:13
okay so now comes to the auto encoder

406
0:13 --> 0:13:16,399
part

407
0:13:16,399 --> 0:13:18,720
so what is the plan now we have an image

408
0:13:18,720 --> 0:13:21,120
we need to encode and we need to decode

409
0:13:21,120 --> 0:13:24,160
this image so i built a model

410
0:13:24,160 --> 0:13:27,200
i mean i have a file called models

411
0:13:27,200 --> 0:13:29,680
where i have a function to build

412
0:13:29,680 --> 0:13:30,639
autoencoder

413
0:13:30,639 --> 0:13:33,760
let's go through that now okay so i'll

414
0:13:33,760 --> 0:13:35,680
share this again with you this one

415
0:13:35,680 --> 0:13:38,800
what i have defined is a a convolutional

416
0:13:38,800 --> 0:13:40,160
block

417
0:13:40,160 --> 0:13:42,079
a function that that builds a

418
0:13:42,079 --> 0:13:43,360
convolutional block

419
0:13:43,360 --> 0:13:46,320
that has conver two convolutional layers

420
0:13:46,320 --> 0:13:46,800
and

421
0:13:46,800 --> 0:13:48,639
of course activation for each of these

422
0:13:48,639 --> 0:13:51,120
layers and batch normalization so this

423
0:13:51,120 --> 0:13:52,959
is a convolutional block

424
0:13:52,959 --> 0:13:55,440
and then i have a encoder block what an

425
0:13:55,440 --> 0:13:57,440
encoder block is basically a convolution

426
0:13:57,440 --> 0:13:58,079
block

427
0:13:58,079 --> 0:14:01,120
plus a pooling layer that's it

428
0:14:01,120 --> 0:14:03,519
this is again nothing new unit we have

429
0:14:03,519 --> 0:14:04,959
built a unit this way

430
0:14:04,959 --> 0:14:07,360
okay so a unit is basically a

431
0:14:07,360 --> 0:14:08,639
convolution block

432
0:14:08,639 --> 0:14:10,800
plus max pooling right so and then you

433
0:14:10,800 --> 0:14:12,639
keep going and then you do the decoder

434
0:14:12,639 --> 0:14:13,600
block

435
0:14:13,600 --> 0:14:16,639
okay so so far i hope makes sense this

436
0:14:16,639 --> 0:14:17,920
is my encoder block

437
0:14:17,920 --> 0:14:19,839
a block of uh you know to build my

438
0:14:19,839 --> 0:14:22,240
encoder the decoder block is uh

439
0:14:22,240 --> 0:14:24,560
exactly opposite instead of convolution

440
0:14:24,560 --> 0:14:26,560
i have transposed convolution

441
0:14:26,560 --> 0:14:29,199
yeah to go the other way think of this

442
0:14:29,199 --> 0:14:31,440
as upscaling i have made a video on this

443
0:14:31,440 --> 0:14:32,160
topic

444
0:14:32,160 --> 0:14:33,760
difference between upscaling and

445
0:14:33,760 --> 0:14:35,360
converting transpose

446
0:14:35,360 --> 0:14:36,800
please watch that video if you don't

447
0:14:36,800 --> 0:14
know what the difference is between

448
0:14 --> 0:14:39,600
these two but either way

449
0:14:39,600 --> 0:14
in the decoder part we are going to use

450
0:14 --> 0:14:43,519
along the decoder path

451
0:14:43,519 --> 0:14:45,440
we are going to use convert2d and the

452
0:14:45,440 --> 0:14:46,720
convolutional block

453
0:14:46,720 --> 0:14:50,320
okay this is again our decoder side so

454
0:14:50,320 --> 0:14:52,800
let's go ahead and build our encoder

455
0:14:52,800 --> 0:14:54,800
build our encoder yeah going from

456
0:14:54,800 --> 0:14:57,360
a large image to the smaller how do you

457
0:14:57,360 --> 0:14:58,079
do that

458
0:14:58,079 --> 0:15:01,120
my encoder block right there we have my

459
0:15:01,120 --> 0:15
encoder block

460
0:15 --> 0:15:04,240
i'm repeating that four times it's up to

461
0:15:04,240 --> 0:15:05,920
you how deep you want to build

462
0:15:05,920 --> 0:15:07,839
the reason i built it this way is i

463
0:15:07,839 --> 0:15:09,839
would like to use exactly the same

464
0:15:09,839 --> 0:15:13,279
encoder when i build my unit later on

465
0:15:13,279 --> 0:15:14,560
when i build my unit

466
0:15:14,560 --> 0:15:17,519
i would use exactly the same structure

467
0:15:17,519 --> 0:15:19,120
this is why i can use the weights from

468
0:15:19,120 --> 0:15:19,839
there

469
0:15:19,839 --> 0:15:22,240
to here okay that's the whole goal here

470
0:15:22,240 --> 0:15:23,199
okay so

471
0:15:23,199 --> 0:15:25,199
i'm going to build my encoder using four

472
0:15:25,199 --> 0:15:26,880
of these and progressively i'm

473
0:15:26,880 --> 0:15:28,720
increasing the number of filters from 64

474
0:15:28,720 --> 0:15:31,680
to 128 to 56 512 and 1024

475
0:15:31,680 --> 0:15:33,440
and progressively your image gets

476
0:15:33,440 --> 0:15:35,120
smaller as you go why does

477
0:15:35,120 --> 0:15:36,720
your image get smaller because in our

478
0:15:36,720 --> 0:15:39,040
convolutional block you have

479
0:15:39,040 --> 0:15:42,560
by three kernel that kind of brings your

480
0:15:42,560 --> 0:15:43,040
image

481
0:15:43,040 --> 0:15:45,600
uh smaller and smaller as you go through

482
0:15:45,600 --> 0:15:47,120
these layers i hope you you know the

483
0:15:47,120 --> 0:15:48,480
basics of that right

484
0:15:48,480 --> 0:15:50,720
so that's building the encoder and what

485
0:15:50,720 --> 0:15:51,759
does the encoder

486
0:15:51,759 --> 0:15:53,920
give out as outputs we are actually

487
0:15:53,920 --> 0:15:55,839
getting two things as outputs

488
0:15:55,839 --> 0:15:58,720
uh for auto encoder we are not going to

489
0:15:58,720 --> 0:16:00,399
use both we are just going to use one

490
0:16:00,399 --> 0:16:02,480
output but what is my encoder block

491
0:16:02,480 --> 0:16:04,560
giving out it's actually giving out

492
0:16:04,560 --> 0:16:06,800
the output of convolution block and also

493
0:16:06,800 --> 0:16:08,399
the output after

494
0:16:08,399 --> 0:16:10,560
the pooling that's it the whole point of

495
0:16:10,560 --> 0:16:11,519
encoder block

496
0:16:11,519 --> 0:16:14,399
is to make sure we get two outputs one

497
0:16:14,399 --> 0:16:14,720
is

498
0:16:14,720 --> 0:16:16,880
an output of just the convolution block

499
0:16:16,880 --> 0:16:17,920
and the output

500
0:16:17,920 --> 0:16:20,639
after max pooling why because in unit

501
0:16:20,639 --> 0:16:23,279
remember the skip connection part

502
0:16:23,279 --> 0:16:25,600
the x the output of convolution block is

503
0:16:25,600 --> 0:16:27,360
what's being added

504
0:16:27,360 --> 0:16:30,399
to the next level in the decoder okay

505
0:16:30,399 --> 0:16:32,639
again these i assume you know these

506
0:16:32,639 --> 0:16:34,800
basics otherwise this this video can be

507
0:16:34,800 --> 0:16:36,560
one of the most confusing videos

508
0:16:36,560 --> 0:16:38,720
that you have ever watched on my channel

509
0:16:38,720 --> 0:16:39,600
so

510
0:16:39,600 --> 0:16:41,199
so far we are trying to build an auto

511
0:16:41,199 --> 0:16:42,800
encoder and you may be thinking why are

512
0:16:42,800 --> 0:16:44,160
you complicating things

513
0:16:44,160 --> 0:16:46,560
uh auto encoder is easy just put like 10

514
0:16:46,560 --> 0:16:49,120
lines of model.ad model.add yes

515
0:16:49,120 --> 0:16:51,199
you will be right but the whole point of

516
0:16:51,199 --> 0:16:52,880
this video is to show

517
0:16:52,880 --> 0:16:55,120
how the same encoder that i'm going to

518
0:16:55,120 --> 0:16:56,079
build

519
0:16:56,079 --> 0:16:59,279
is going to be used also in unit so once

520
0:16:59,279 --> 0:17:01,040
we train this encoder and get the

521
0:17:01,040 --> 0:17:01,680
weights

522
0:17:01,680 --> 0:17:03,279
those weights can be transferred to the

523
0:17:03,279 --> 0:17:05,360
unit okay that's that's our goal

524
0:17:05,360 --> 0:17:08,559
so now you know how to build encoder

525
0:17:08,559 --> 0:17:12,160
just these five blocks and then

526
0:17:12,160 --> 0:17:14,880
my decoder goes from this point and then

527
0:17:14,880 --> 0:17
symmetrically

528
0:17 --> 0:17:18,079
goes the other way right so 10 24 and

529
0:17:18,079 --> 0:17:21,280
then 512 256 128 and 64. that's exactly

530
0:17:21,280 --> 0:17:22,400
what i'm doing right there

531
0:17:22,400 --> 0:17:25,120
going the other way and then finally it

532
0:17:25,120 --> 0:17:25,919
gives me

533
0:17:25,919 --> 0:17:29,120
a decoded image of uh of

534
0:17:29,120 --> 0:17:31,440
whatever the input is with 3 channel

535
0:17:31,440 --> 0:17
output 256 by 256 by 3 right so that's

536
0:17 --> 0:17:35,600
exactly what we are doing

537
0:17:35,600 --> 0:17:38,960
and uh anything anything i think that's

538
0:17:38,960 --> 0:17:39,760
that should be

539
0:17:39,760 --> 0:17:42,400
it and when we build an auto encoder

540
0:17:42,400 --> 0:17:43,280
it's basically

541
0:17:43,280 --> 0:17:45,679
encoder plus decoder that's it right

542
0:17:45,679 --> 0:17:47,280
that's that's our auto encoder

543
0:17:47,280 --> 0:17:49,200
that's exactly what i'm doing my input

544
0:17:49,200 --> 0:17:50,960
is going to be my input image with the

545
0:17:50,960 --> 0:17:52,080
shape of that

546
0:17:52,080 --> 0:17:55,520
and my auto encoder model is basically

547
0:17:55,520 --> 0:17:59,280
my input and then this is my output

548
0:17:59,280 --> 0:17:59,600
right

549
0:17:59,600 --> 0:18:01,280
how do you define a model your input and

550
0:18:01,280 --> 0:18:03,520
output input is my input image what is

551
0:18:03,520 --> 0:18:05,760
your output your output is basically

552
0:18:05,760 --> 0:18:06,320
that

553
0:18:06,320 --> 0:18:08,960
a decoded image and how do i define that

554
0:18:08,960 --> 0:18:09,840
here which is

555
0:18:09,840 --> 0:18:13,440
nothing but build decoder build decoder

556
0:18:13,440 --> 0:18:15,360
and the input to the decoder is my

557
0:18:15,360 --> 0:18:17,600
encoded image which is basically

558
0:18:17,600 --> 0:18:21,280
that i hope this makes sense again

559
0:18:21,280 --> 0:18:22,799
some people may think this is too basic

560
0:18:22,799 --> 0:18:24,320
some of you may think hey what are you

561
0:18:24,320 --> 0:18:25,520
talking about but

562
0:18:25,520 --> 0:18:26,880
watch this video a couple of times

563
0:18:26,880 --> 0:18:29,120
practice this and and things will make

564
0:18:29,120 --> 0:18:30,240
sense this is a great

565
0:18:30,240 --> 0:18:32,559
great way of learning about uh you know

566
0:18:32,559 --> 0:18
these neural networks okay

567
0:18 --> 0:18:36,640
so much about discussing the model let's

568
0:18:36,640 --> 0:18:37,679
just go ahead

569
0:18:37,679 --> 0:18:40,559
and import our build auto encoder the

570
0:18:40,559 --> 0:18
function that we just

571
0:18 --> 0:18:43,840
defined that builds the auto encoder

572
0:18:43,840 --> 0:18:46,160
what does the build.auto encoder need

573
0:18:46,160 --> 0:18
it requires the shape of my image and

574
0:18 --> 0:18:50,720
what is the shape 256 by 256x3

575
0:18:50,720 --> 0:18:52,480
so let's go ahead and build this auto

576
0:18:52,480 --> 0:18:54,720
encoder so it's building it right now

577
0:18:54,720 --> 0:18:57,200
basically when i say build auto encoder

578
0:18:57,200 --> 0:19:00,160
it's putting together this model

579
0:19:00,160 --> 0:19:02,720
with input image size as input input

580
0:19:02,720 --> 0:19:05,039
image as the input and then the decoded

581
0:19:05,039 --> 0:19:07,280
as the output that's exactly what it did

582
0:19:07,280 --> 0:19:08,880
now let's go ahead and compile the model

583
0:19:08,880 --> 0:19:10,640
how do you compile an auto encoder

584
0:19:10,640 --> 0:19:13,440
well let's use an optimizer called atom

585
0:19:13,440 --> 0:19:15,280
this this works in most scenarios

586
0:19:15,280 --> 0:19:17,200
and for loss let's use mean squared

587
0:19:17,200 --> 0:19:19,200
error why this is not a regression

588
0:19:19,200 --> 0:19:20,559
problem why are we using mean squared

589
0:19:20,559 --> 0:19:22,160
error well in a way this is a regression

590
0:19:22,160 --> 0:19:23,280
problem because we are

591
0:19:23,280 --> 0:19
trying to minimize the error between the

592
0:19 --> 0:19:26,799
output

593
0:19:26,799 --> 0:19:29,440
and the input images right we are trying

594
0:19:29,440 --> 0:19:30,799
to minimize this

595
0:19:30,799 --> 0:19:32,880
reconstruction error between the output

596
0:19:32,880 --> 0:19:34,160
and input

597
0:19:34,160 --> 0:19:36,799
and if there is no error i get the same

598
0:19:36,799 --> 0:19:38,080
output as the same input

599
0:19:38,080 --> 0:19:40,240
that's why i'm using mean squared error

600
0:19:40,240 --> 0:19:42,320
and we can track the metrics accuracy so

601
0:19:42,320 --> 0:19:44,400
let's go ahead and build that

602
0:19:44,400 --> 0:19:46,559
and now let's print the model summary

603
0:19:46,559 --> 0:19:48,160
this is basically

604
0:19:48,160 --> 0:19:50,480
my encoder decoder network so i start

605
0:19:50,480 --> 0:19:53,200
with 256 to 563

606
0:19:53,200 --> 0:19:54,640
and then increase the number of filters

607
0:19:54,640 --> 0:19:56,880
to 64. as you know we

608
0:19:56,880 --> 0:20:00,320
did that 64 to 128 128 to

609
0:20:00,320 --> 0:20:03,360
256 so the filters increase the size

610
0:20:03,360 --> 0:20:05,600
goes down by half each time yeah the

611
0:20:05,600 --> 0:20:06,640
filters go up

612
0:20:06,640 --> 0:20:11,200
by two times okay i think 16 16 to 10 24

613
0:20:11,200 --> 0:20:12,799
is the last one and then it goes up

614
0:20:12,799 --> 0:20:14,880
symmetrically 32 32 5 12

615
0:20:14,880 --> 0:20:18,320
64 64 and finally we'll end up with 256

616
0:20:18,320 --> 0:20:19,200
to 56

617
0:20:19,200 --> 0:20:21,520
image and there are about 28 million

618
0:20:21,520 --> 0:20:23,440
parameters that need to be trained

619
0:20:23,440 --> 0:20:25,120
but don't worry this is just single

620
0:20:25,120 --> 0:20:26,559
image so it's going to be super fast

621
0:20:26,559 --> 0:20:27,840
when we train it because

622
0:20:27,840 --> 0:20:29,280
there's not much data even though there

623
0:20:29,280 --> 0:20:30,960
are 28 million parameters that need to

624
0:20:30,960 --> 0:20:31,840
be adjusted

625
0:20:31,840 --> 0:20:33,600
but i really want to make sure you

626
0:20:33,600 --> 0:20:35,039
understand this

627
0:20:35,039 --> 0:20:36,799
you know what we're trying to do and

628
0:20:36,799 --> 0:20:38,799
let's go ahead and model.fit

629
0:20:38,799 --> 0:20:40,799
my input is image array my output is

630
0:20:40,799 --> 0:20:43,120
image array normally you give x and y

631
0:20:43,120 --> 0:20:45,600
in my case x equals to i because this is

632
0:20:45,600 --> 0:20:46,960
an auto encoder we are

633
0:20:46,960 --> 0:20:49,280
encoding decoding okay and let's run

634
0:20:49,280 --> 0:20:51,679
this for 500 epochs

635
0:20:51,679 --> 0:20:54,880
and while it's running it should be

636
0:20:54,880 --> 0:20:57,200
pretty fast actually

637
0:20:57,200 --> 0:20:59,520
especially if you have a gpu yeah there

638
0:20:59,520 --> 0:21:01,280
you go it should be done in a minute or

639
0:21:01,280 --> 0:21:02,080
so but uh

640
0:21:02,080 --> 0:21:04,960
just want to confirm one one final time

641
0:21:04,960 --> 0:21:06,159
but i just want to

642
0:21:06,159 --> 0:21:08,960
reinforce this message one final time

643
0:21:08,960 --> 0:21:09,760
what we're doing

644
0:21:09,760 --> 0:21:13,360
is an auto encoder where we did build

645
0:21:13,360 --> 0:21:16,960
an encoder that goes from some size

646
0:21:16,960 --> 0:21:19,760
to smaller size incrementally because we

647
0:21:19,760 --> 0:21:20,400
have this

648
0:21:20,400 --> 0:21:22,720
max pooling uh sorry uh yeah these and

649
0:21:22,720 --> 0:21:24,320
max pooling operations right there the

650
0:21:24,320 --> 0:21:26,480
convolution and max pooling operations

651
0:21:26,480 --> 0:21:28,240
and then the number of filters are going

652
0:21:28,240 --> 0:21:29,679
up incrementally exactly

653
0:21:29,679 --> 0:21:32,159
opposite is happening in decoder so as

654
0:21:32,159 --> 0:21:34,400
you can imagine when i get down to unit

655
0:21:34,400 --> 0:21:37,440
i'm using the same encoder but then a

656
0:21:37,440 --> 0:21:39,360
different decoder

657
0:21:39,360 --> 0:21:41,280
yeah if you just use the same decoder

658
0:21:41,280 --> 0:21:43,039
then it's an auto encoder decoder

659
0:21:43,039 --> 0:21:44,159
because

660
0:21:44,159 --> 0:21:46,480
decoder block for unit decoder block for

661
0:21:46,480 --> 0:21:47,919
unit needs the skip

662
0:21:47,919 --> 0:21:49,520
features and we already know where the

663
0:21:49,520 --> 0:21:51,200
skip features are coming from

664
0:21:51,200 --> 0:21:54,559
these are the skip features that that we

665
0:21:54,559 --> 0:21:57,120
get from here

666
0:21:57,120 --> 0:22:00,240
where is it where is it yeah so these

667
0:22:00,240 --> 0:22:01,200
are the features

668
0:22:01,200 --> 0:22:02,640
okay there you go the training is done

669
0:22:02,640 --> 0:22:04,640
so let's go ahead and reconstruct

670
0:22:04,640 --> 0:22:07,200
like predict on the mar you know uh on

671
0:22:07,200 --> 0:22:09,200
my uh on my original image

672
0:22:09,200 --> 0:22:11,440
so hopefully it should reconstruct a

673
0:22:11,440 --> 0:22:13,440
decent image so let's go ahead and print

674
0:22:13,440 --> 0:22:14,400
out the original

675
0:22:14,400 --> 0:22:16,559
and the reconstructed image that's not

676
0:22:16,559 --> 0:22:18,559
that's not a good reconstruction so what

677
0:22:18,559 --> 0:22:20,640
kind of accuracy 93 right

678
0:22:20,640 --> 0:22:23,280
so let's do this if you move one more

679
0:22:23,280 --> 0:22:24,080
time

680
0:22:24,080 --> 0:22:25,919
and i'll pause the videos i i won't

681
0:22:25,919 --> 0:22:27,919
waste your time and i'll pause the video

682
0:22:27,919 --> 0:22:28,880
and then let's uh

683
0:22:28,880 --> 0:22:32,480
let's see how dramatically it comes i i

684
0:22:32,480 --> 0:22:33,440
remember if i

685
0:22:33,440 --> 0:22:35,600
did this like 1000 epochs or something

686
0:22:35,600 --> 0:22:38,320
then then the accuracy was super amazing

687
0:22:38,320 --> 0:22:40,480
okay so let me pause this and then

688
0:22:40,480 --> 0:22
continue within literally a few seconds

689
0:22 --> 0:22:46,960
and uh yeah few seconds later now we had

690
0:22:46,960 --> 0:22
about 93

691
0:22 --> 0:22:50,480
accuracy now this is about 96 and let's

692
0:22:50,480 --> 0:22:51,039
see

693
0:22:51,039 --> 0:22:53,360
if it made any uh any difference so what

694
0:22:53,360 --> 0:22:54,480
do we need to do

695
0:22:54,480 --> 0:22:56,799
let's go ahead and predict this one more

696
0:22:56,799 --> 0:22:57,919
time using the new

697
0:22:57,919 --> 0:23:01,039
model and let's print this

698
0:23:01,039 --> 0:23:04,480
again oh there you go right

699
0:23:04,480 --> 0:23:06,480
so this is with 500 epochs this is how

700
0:23:06,480 --> 0:23
the construction is and

701
0:23 --> 0:23:10,159
extra 500 epochs this is where we got

702
0:23:10,159 --> 0:23:11,919
almost identical i mean i can see some

703
0:23:11,919 --> 0:23:13,039
difference in color

704
0:23:13,039 --> 0:23:15,280
this is three channel image right but

705
0:23:15,280 --> 0:23:17,280
then look look how good this is this is

706
0:23:17,280 --> 0:23:18,080
a bit

707
0:23:18,080 --> 0:23:20,799
blurred compared to this one but amazing

708
0:23:20,799 --> 0:23:21,280
but

709
0:23:21,280 --> 0:23:23,679
our goal is not to reconstruct the best

710
0:23:23,679 --> 0:23:25,280
image our goal is to make sure we

711
0:23:25,280 --> 0:23:26,559
reconstruct it as

712
0:23:26,559 --> 0:23:29,120
good as possible but then take the

713
0:23:29,120 --> 0:23:31,120
weights from the encoder so just to show

714
0:23:31,120 --> 0:23:32,320
you that part

715
0:23:32,320 --> 0:23:33,919
not not how to take the weights i'll

716
0:23:33,919 --> 0:23:35,360
save that for the next video because i

717
0:23:35,360 --> 0:23:36,799
don't want to make this a one

718
0:23:36,799 --> 0:23:40,880
one hour long video so let's look at

719
0:23:40,880 --> 0:23:42,400
the features how do you look at the

720
0:23:42,400 --> 0:23:44,400
features from your model

721
0:23:44,400 --> 0:23:47,600
so first of all let's build another

722
0:23:47,600 --> 0:23:49,200
model

723
0:23:49,200 --> 0:23:50,799
another auto encoder so this is

724
0:23:50,799 --> 0:23:52,880
basically remember here

725
0:23:52,880 --> 0:23:56,720
we built a auto encoder right there

726
0:23:56,720 --> 0:23:59,200
and then we compiled and then we trained

727
0:23:59,200 --> 0:24:00,559
now i just want

728
0:24:00,559 --> 0:24:02,880
an auto encoder that hasn't been trained

729
0:24:02,880 --> 0:24:03,600
meaning

730
0:24:03,600 --> 0:24:06,720
with random weights why am i doing this

731
0:24:06,720 --> 0:24:08,480
just so we can look at features before

732
0:24:08,480 --> 0:24:10,880
and after that's it no other reason

733
0:24:10,880 --> 0:24:13,440
and then i'll put i'll make my model the

734
0:24:13,440 --> 0:24:15,679
current model i want to use as model 2

735
0:24:15,679 --> 0:24:17,200
which we just defined

736
0:24:17,200 --> 0:24:20,320
and we are going to get our outputs as

737
0:24:20,320 --> 0:24:22,400
layer.output for each layer

738
0:24:22,400 --> 0:24:25,279
in my model starting with first one yeah

739
0:24:25,279 --> 0:24:26,880
the zeroth one is the input

740
0:24:26,880 --> 0:24:29,360
and then go ahead after the first one so

741
0:24:29,360 --> 0:24:30,080
this

742
0:24:30,080 --> 0:24:32,960
line when i run it you will see that my

743
0:24:32,960 --> 0:24:33,679
outputs

744
0:24:33,679 --> 0:24:37,039
right there has 63

745
0:24:37,039 --> 0:24:39,600
size of 63 it's a list of 63 keras

746
0:24:39,600 --> 0:24:40,480
tensors

747
0:24:40,480 --> 0:24:42,480
okay these are the 63 layers i have in

748
0:24:42,480 --> 0:24:43,919
my auto encoder

749
0:24:43,919 --> 0:24:47,279
okay now uh let's define a model for

750
0:24:47,279 --> 0:24:49,440
visualization which is basically

751
0:24:49,440 --> 0:24:51,919
my inputs is nothing but the inputs

752
0:24:51,919 --> 0:24:53,120
coming from this model

753
0:24:53,120 --> 0:24:56,159
which is the input or input image and my

754
0:24:56,159 --> 0:24:56,720
outputs

755
0:24:56,720 --> 0:24:58,720
is just the outputs that i just defined

756
0:24:58,720 --> 0:25:01,279
here which means if you do this you'll

757
0:25:01,279 --> 0:25:02,559
get 63 different

758
0:25:02,559 --> 0:25:04,880
outputs each one corresponding to each

759
0:25:04,880 --> 0:25:05,600
layer here

760
0:25:05,600 --> 0:25:08,080
which gives us everything we need for

761
0:25:08,080 --> 0:25:08,880
plotting

762
0:25:08,880 --> 0:25:12,159
so let's go ahead and define this model

763
0:25:12,159 --> 0:25:14,400
and we just defined the model we need to

764
0:25:14,400 --> 0:25:16,480
predict using that model

765
0:25:16,480 --> 0:25:18,240
remember we haven't trained on this one

766
0:25:18,240 --> 0:25:20,640
right so let's define my input image is

767
0:25:20,640 --> 0:25:21,760
basically my image

768
0:25:21,760 --> 0:25:25,039
array which we just did earlier right i

769
0:25:25,039 --> 0:25:26,880
mean that's what we called it yeah

770
0:25:26,880 --> 0:25:29,760
the mona lisa image and let's generate

771
0:25:29,760 --> 0:25:31,279
our feature maps feature maps is

772
0:25:31,279 --> 0:25:32,400
basically

773
0:25:32,400 --> 0:25
this new model we defined dot predict

774
0:25 --> 0:25:38,799
on my image and when we do that we

775
0:25:38,799 --> 0:25
should get 63

776
0:25 --> 0:25:42,320
outputs hopefully feature image feature

777
0:25:42,320 --> 0:25:44,720
maps 63 numpy arrays

778
0:25:44,720 --> 0:25:47,840
y63 again we have 63 layers that's why

779
0:25:47,840 --> 0:25:49,919
we defined our output equal to outputs

780
0:25:49,919 --> 0:25:52,960
we get 63 layers and now i have 63

781
0:25:52,960 --> 0:25:54,480
feature maps just pick which one you

782
0:25:54,480 --> 0:25:56,799
want to plot that's exactly what the

783
0:25:56,799 --> 0:25:57,840
bottom part does

784
0:25:57,840 --> 0:26:00,080
so let's look at just single layer i'll

785
0:26:00,080 --> 0:26:01,600
share the code you can experiment with

786
0:26:01,600 --> 0:26:02,080
this

787
0:26:02,080 --> 0:26:03,840
let's look at the last layer 30 second

788
0:26:03,840 --> 0:26:06,159
layer well 63rd layer is the last layer

789
0:26:06,159 --> 0:26:08,240
but 32nd layer is the last layer of

790
0:26:08,240 --> 0:26:10,400
autoencoder exactly halfway through

791
0:26:10,400 --> 0:26:12,880
okay so let's look at uh the layer

792
0:26:12,880 --> 0:26:14,320
number 32

793
0:26:14,320 --> 0:26:18,320
and let's plot my original image

794
0:26:18,320 --> 0:26:21,039
and the feature map okay right actually

795
0:26:21,039 --> 0:26:22,640
i'm not plotting original mm

796
0:26:22,640 --> 0:26:25,200
feature map sorry let's plot each

797
0:26:25,200 --> 0:26:27,440
feature maps as a grid of eight by eight

798
0:26:27,440 --> 0:26:29,440
so we'll get 64 feature maps

799
0:26:29,440 --> 0:26:32,320
okay for the layer number 32. so let's

800
0:26:32,320 --> 0:26:33,200
go ahead

801
0:26:33,200 --> 0:26:36,840
and plot it and right now it's

802
0:26:36,840 --> 0:26:38,080
predicting

803
0:26:38,080 --> 0:26:39,919
uh sorry it's plotting each one of these

804
0:26:39,919 --> 0:26:41,279
and there you go

805
0:26:41,279 --> 0:26:43,120
i already showed you this as part of the

806
0:26:43,120 --> 0:26:44,559
presentation i just want to make sure

807
0:26:44,559 --> 0:26:45,200
you see it

808
0:26:45,200 --> 0:26:48,400
live and this is based on uh

809
0:26:48,400 --> 0:26:51,520
random weights

810
0:26:51,520 --> 0:26:54,640
now let's use the trained weights how

811
0:26:54,640 --> 0:26:55,360
does the

812
0:26:55,360 --> 0:26:57,279
you know the the feature maps uh how do

813
0:26:57,279 --> 0:26:59,520
they look like so let's go ahead and run

814
0:26:59,520 --> 0:27:02,240
all of these lines and then finally plot

815
0:27:02,240 --> 0:27:04,240
them once we have it

816
0:27:04,240 --> 0:27:07,360
go ahead and plot it and

817
0:27:07,360 --> 0:27:08,880
hopefully we should see some structure

818
0:27:08,880 --> 0:27:11,760
there you go nice structures right there

819
0:27:11,760 --> 0:27:15,440
okay so i hope you got the point of

820
0:27:15,440 --> 0:27:18,399
using are the benefits of pre-trained

821
0:27:18,399 --> 0:27:19,200
models

822
0:27:19,200 --> 0:27:22,080
now you can use for example the imagenet

823
0:27:22,080 --> 0:27:22,640
weights

824
0:27:22,640 --> 0:27:24,320
that definitely helps this is what we

825
0:27:24,320 --> 0:27:25,760
call transfer learning

826
0:27:25,760 --> 0:27:28,799
but imagenet is a bunch of animals and

827
0:27:28,799 --> 0:27:31,200
trucks and these type of things right if

828
0:27:31,200 --> 0:27:32,399
you really want to work

829
0:27:32,399 --> 0:27:35,360
on a bunch of electron microscopy images

830
0:27:35,360 --> 0:27:37,120
where you want to detect mitochondria or

831
0:27:37,120 --> 0:27:38,559
whether you're in material science or

832
0:27:38,559 --> 0:27:39,200
whether

833
0:27:39,200 --> 0:27:41,279
if you want to perform semantic

834
0:27:41,279 --> 0:27:43,039
segmentation on

835
0:27:43,039 --> 0:27:45,520
on satellite images it does make sense

836
0:27:45,520 --> 0:27:47,440
to collect as many satellite images as

837
0:27:47,440 --> 0:27:48,480
possible

838
0:27:48,480 --> 0:27:50,880
train an auto encoder get the weights

839
0:27:50,880 --> 0:27:53,120
and use those weights as starting point

840
0:27:53,120 --> 0:27:54,960
for transfer learning and then do

841
0:27:54,960 --> 0:27:56,720
semantic segmentation this is exactly

842
0:27:56,720 --> 0:27:57,840
what we're going to do in the next

843
0:27:57,840 --> 0:27:58,640
tutorial

844
0:27:58,640 --> 0:28:00,159
in the next now that you understand what

845
0:28:00,159 --> 0:28:01,919
autoencoder is in the next tutorial

846
0:28:01,919 --> 0:28:04,320
we're going to train an auto encoder

847
0:28:04,320 --> 0:28:06,159
save the weights on bunch of images not

848
0:28:06,159 --> 0:28:09,039
just one image a whole bunch of images

849
0:28:09,039 --> 0:28:11,279
save the weights and use those weights

850
0:28:11,279 --> 0:28:12,559
to train a unit

851
0:28:12,559 --> 0:28:14,159
okay so please stay tuned for the next

852
0:28:14,159 --> 0:28
video hopefully you'll find

853
0:28 --> 0:28
it useful ok thank you guys don't forget

854
0:28 --> 0:28:20,880
to subscribe

